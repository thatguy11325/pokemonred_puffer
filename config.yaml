wandb:
  entity: thatguy11325
  project: pokemon
  group: ~

debug:
  env:
    headless: False
    stream_wrapper: False
    init_state: victory_road
    max_steps: 16
    log_frequency: 1
    disable_wild_encounters: True
    disable_ai_actions: True
    use_global_map: False
    reduce_res: False
  train:
    device: cpu
    compile: False
    compile_mode: default
    num_envs: 1
    num_workers: 1
    env_batch_size: 4
    env_pool: True
    zero_copy: False
    batch_size: 128
    minibatch_size: 4
    batch_rows: 4
    bptt_horizon: 2
    total_timesteps: 100_000_000
    save_checkpoint: True
    checkpoint_interval: 4
    save_overlay: True
    overlay_interval: 1
    verbose: False
    env_pool: False
    load_optimizer_state: False
    # swarm_frequency: 10
    # swarm_keep_pct: .1

env:
  headless: True
  save_final_state: True
  print_rewards: True
  video_dir: video
  state_dir: pyboy_states
  init_state: Bulbasaur
  action_freq: 24
  max_steps: 20480
  save_video: False
  fast_video: False
  frame_stacks: 1
  perfect_ivs: True
  reduce_res: True
  two_bit: True
  log_frequency: 1000
  auto_flash: True
  disable_wild_encounters: True
  disable_ai_actions: False
  auto_teach_cut: True
  auto_use_cut: True
  auto_use_surf: True
  auto_teach_surf: True
  auto_teach_strength: True
  auto_solve_strength_puzzles: True
  auto_remove_all_nonuseful_items: True
  auto_pokeflute: True
  infinite_money: True
  use_global_map: False
  save_state: False


train:
  seed: 1
  torch_deterministic: True
  device: cuda
  compile: True
  compile_mode: "reduce-overhead"
  float32_matmul_precision: "high"
  total_timesteps: 100_000_000_000
  batch_size: 65536 
  minibatch_size: 2048
  learning_rate: 2.0e-4
  anneal_lr: False
  gamma: 0.998
  gae_lambda: 0.95
  num_minibatches: 4
  update_epochs: 3
  norm_adv: True
  clip_coef: 0.1
  clip_vloss: True
  ent_coef: 0.01
  vf_coef: 0.5
  max_grad_norm: 0.5
  target_kl: ~
  batch_rows: 128
  bptt_horizon: 16 
  vf_clip_coef: 0.1

  num_envs: 288
  num_workers: 24
  env_batch_size: 72
  env_pool: True
  zero_copy: False

  verbose: False
  data_dir: runs
  save_checkpoint: False
  checkpoint_interval: 200
  save_overlay: True
  overlay_interval: 100
  cpu_offload: False
  pool_kernel: [0]
  load_optimizer_state: False
  use_rnn: True
  async_wrapper: False

  # swarm_frequency: 500
  # swarm_keep_pct: .8

wrappers:
  empty:
    - episode_stats.EpisodeStatsWrapper: {}

  baseline:
    - stream_wrapper.StreamWrapper:
        user: thatguy
    - exploration.DecayWrapper:
        step_forgetting_factor:
          npc: 0.995
          coords: 0.9995
          map_ids: 0.995
          explore: 0.9995
          start_menu: 0.998
          pokemon_menu: 0.998
          stats_menu: 0.998
          bag_menu: 0.998
          action_bag_menu: 0.998
        forgetting_frequency: 10
    - exploration.OnResetExplorationWrapper:
        full_reset_frequency: 1
        jitter: 0
  
  finite_coords:
    - stream_wrapper.StreamWrapper:
        user: thatguy
    - exploration.MaxLengthWrapper:
        capacity: 1750
    - exploration.OnResetExplorationWrapper:
        full_reset_frequency: 1
        jitter: 0

  stream_only:
    - stream_wrapper.StreamWrapper:
        user: thatguy 
    - exploration.OnResetExplorationWrapper:
        full_reset_frequency: 1
        jitter: 1

  fixed_reset_value:
    - stream_wrapper.StreamWrapper:
        user: thatguy 
    - exploration.OnResetLowerToFixedValueWrapper:
        fixed_value:
          coords: 0.33
          map_ids: 0.33
          npc: 0.33
          cut: 0.33
          explore: 0.33
    - exploration.OnResetExplorationWrapper:
        full_reset_frequency: 25
        jitter: 0
    - episode_stats.EpisodeStatsWrapper: {}

rewards:
  baseline.BaselineRewardEnv:
    reward:
  baseline.TeachCutReplicationEnv:
    reward:
      event: 1.0
      bill_saved: 5.0
      seen_pokemon: 4.0
      caught_pokemon: 4.0
      moves_obtained: 4.0
      hm_count: 10.0
      level: 1.0
      badges: 10.0
      exploration: 0.02
      cut_coords: 1.0
      cut_tiles: 1.0
      start_menu: 0.01
      pokemon_menu: 0.1
      stats_menu: 0.1
      bag_menu: 0.1

  baseline.TeachCutReplicationEnvFork:
    reward:
      event: 1.0
      bill_saved: 5.0
      moves_obtained: 4.0
      hm_count: 10.0
      badges: 10.0
      exploration: 0.02
      cut_coords: 1.0
      cut_tiles: 1.0
      start_menu: 0.01
      pokemon_menu: 0.1
      stats_menu: 0.1
      bag_menu: 0.1
      taught_cut: 10.0
      explore_npcs: 0.02
      explore_hidden_objs: 0.02

  baseline.CutWithObjectRewardsEnv:
    reward:
      event: 1.0
      bill_saved: 5.0
      seen_pokemon: 4.0
      caught_pokemon: 4.0
      moves_obtained: 4.0
      hm_count: 10.0
      level: 1.0
      badges: 10.0
      exploration: 0.02
      cut_coords: 0.0
      cut_tiles: 0.0
      start_menu: 0.00
      pokemon_menu: 0.0
      stats_menu: 0.0
      bag_menu: 0.1
      rocket_hideout_found: 5.0
      explore_hidden_objs: 0.02
      seen_action_bag_menu: 0.1
  
  baseline.CutWithObjectRewardRequiredEventsEnv:
    reward:
      event: 1.0
      seen_pokemon: 4.0
      caught_pokemon: 4.0
      moves_obtained: 4.0
      hm_count: 10.0
      level: 1.0
      badges: 5.0
      exploration: 0.02
      cut_coords: 0.0
      cut_tiles: 0.0
      start_menu: 0.0
      pokemon_menu: 0.0
      stats_menu: 0.0
      bag_menu: 0.0
      explore_hidden_objs: 0.02
      seen_action_bag_menu: 0.0
      required_event: 5.0
      required_item: 5.0
      useful_item: 1.0
      pokecenter_heal: 1.0



policies:
  multi_convolutional.MultiConvolutionalPolicy:
    policy:
      hidden_size: 512

    rnn:
      # Assumed to be in the same module as the policy
      name: MultiConvolutionalRNN
      args:
        input_size: 512
        hidden_size: 512
        num_layers: 1
